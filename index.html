<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="FontCraft, a tool for creating custom fonts for non-experts."
    />
    <meta
      name="keywords"
      content="FontCraft, font, design, typography, font creation"
    />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@yukistachan" />
    <meta name="twitter:creator" content="@yukistachan" />
    <meta
      property="og:url"
      content="https://yukistavailable.github.io/fontcraft.github.io/"
    />
    <meta
      property="og:title"
      content="FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization"
    />
    <meta
      property="og:description"
      content="FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization"
    />
    <meta
      property="og:image"
      content="https://yukistavailable.github.io/hosting/fontcraft_top.png"
    />
    <title>
      FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization
    </title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-V1ND81K2GS"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-V1ND81K2GS");
    </script>
    <!-- Google tag (gtag.js) -->

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="icon" href="./static/images/favicon.svg" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false"
        >
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://yukistavailable.github.io/">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>

          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> More Research </a>
            <div class="navbar-dropdown">
              <a
                class="navbar-item"
                href="https://yukistavailable.github.io/fontclip.github.io/"
              >
                FontCLIP
              </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                FontCraft: Multimodal Font Design Using Interactive Bayesian
                Optimization
              </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://yukistavailable.github.io/">Yuki Tatsukawa</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="https://jdily.github.io/">I-Chao Shen</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="https://dogadogan.com/">Mustafa Doga Dogan</a
                  ><sup>2</sup>,</span
                >
                <br />
                <span class="author-block">
                  <a href="https://anranqi.github.io/">Anran Qi</a><sup>3</sup>,
                </span>
                <span class="author-block">
                  <a href="https://koyama.xyz/">Yuki Koyama</a><sup>4</sup>,
                </span>
                <span class="author-block">
                  <a href="https://faculty.runi.ac.il/arik/site/index.asp"
                    >Ariel Shamir</a
                  ><sup>5</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www-ui.is.s.u-tokyo.ac.jp/~takeo/"
                    >Takeo Igarashi</a
                  ><sup>1</sup>
                </span>
              </div>

              <div class="is-size-6 publication-authors">
                <span class="author-block"
                  ><sup>1</sup>The University of Tokyo, Japan</span
                >
                <span class="author-block"
                  ><sup>2</sup>Adobe Research Basel, Switzerland</span
                >
                <span class="author-block"
                  ><sup>3</sup>Centre Inria d’Université Côte d’AzurSophia
                  Antipolis, France</span
                >
                <span class="author-block"
                  ><sup>4</sup>National Institute of Advanced Industrial Science
                  and Technology (AIST), Japan</span
                >
                <span class="author-block"
                  ><sup>5</sup>Reichman University, Israel</span
                >
              </div>
              <!-- <br/> -->
              <div class="is-size-4">
                <a href="https://chi2025.acm.org/">CHI 2025</a>
              </div>
              <!-- <br/> -->

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper (Coming soon)</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv (Coming soon)</span>
                    </a>
                  </span>
                  <!-- Video Link. -->
                  <span class="link-block">
                    <a
                      href="https://www.youtube.com/watch?v=KKSJQkWfS5o"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span>
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code (Coming soon)</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Teaser -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <img
                src="./static/images/teaser.png"
                class="teaser-image"
                alt="FontCraft teaser image."
              />
            </div>
          </div>
        </div>
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Creating new fonts requires a lot of human effort and
                professional typographic knowledge. Despite the rapid
                advancements of automatic font generation models, existing
                methods require users to prepare pre-designed characters with
                target styles using font-editing software, which poses a problem
                for non-expert users.
              </p>
              <p>
                To address this limitation, we propose FontCraft, a system that
                enables font generation without relying on pre-designed
                characters. Our approach integrates the exploration of a
                font-style latent space with human-in-the-loop preferential
                Bayesian optimization and multimodal references, facilitating
                efficient exploration and enhancing user control. Moreover,
                FontCraft allows users to revisit previous designs, retracting
                their earlier choices in the preferential Bayesian optimization
                process. Once users finish editing the style of a selected
                character, they can propagate it to the remaining characters and
                further refine them as needed. The system then generates a
                complete outline font in OpenType format.
              </p>
              <p>
                We evaluated the effectiveness of FontCraft through a user study
                comparing it to a baseline interface. Results from both
                quantitative and qualitative evaluations demonstrate that
                FontCraft enables non-expert users to design fonts efficiently.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe
                src="https://www.youtube.com/embed/r7ScZHT6CRI?rel=0&amp;showinfo=0"
                frameborder="0"
                allow="autoplay; encrypted-media"
                allowfullscreen
              ></iframe>
            </div>
          </div>
        </div>
        <!--/ Paper video. -->
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Key points</h2>

            <!-- Explore a one-dimensional subspace -->
            <div class="box key-point">
              <h3 class="title is-4">Explore one-dimensional subspace</h3>
              <div class="content has-text-justified">
                <p>
                  Users can design a font by exploring a one-dimensional
                  subspace of the latent space.
                </p>
              </div>
              <div class="columns is-vcentered interpolation-panel">
                <div class="column is-2 has-text-centered">
                  <img
                    src="./static/interpolation/h/0.svg"
                    class="interpolation-image"
                    alt="Interpolate start reference image."
                  />
                  <p>Edge</p>
                </div>
                <div class="column interpolation-video-column">
                  <div id="interpolation-image-wrapper">Loading...</div>
                  <input
                    class="slider is-fullwidth is-large is-info"
                    id="interpolation-slider"
                    step="1"
                    min="0"
                    max="100"
                    value="0"
                    type="range"
                  />
                </div>
                <div class="column is-2 has-text-centered">
                  <img
                    src="./static/interpolation/h/140.svg"
                    class="interpolation-image"
                    alt="Interpolation end reference image."
                  />
                  <p class="is-bold">Edge</p>
                </div>
              </div>
            </div>

            <!-- Search subspace construction -->
            <div class="box key-point">
              <h3 class="title is-4">Search subspace construction</h3>
              <div class="content has-text-justified">
                <p>
                  One-dimensional search subspace is constructed by the
                  preferential Bayesian optimization or multimodal references.
                </p>
              </div>
              <div class="content has-text-centered">
                <div class="content has-text-justified">
                  <img
                    src="./static/images/searchspaceconstruction.png"
                    class="teaser-image"
                    alt="Search subspace construction."
                  />
                </div>
              </div>
            </div>

            <!-- Multimodal references -->
            <div class="box key-point">
              <h3 class="title is-4">Multimodal references</h3>
              <div class="content has-text-justified">
                <p>
                  Users can use multimodal references to guide the exploration.
                  They are handled by
                  <a
                    href="https://yukistavailable.github.io/fontclip.github.io/"
                    >FontCLIP</a
                  >
                  and embedded into the latent space.
                </p>
              </div>
              <div class="content has-text-centered">
                <div class="content has-text-justified">
                  <img
                    src="./static/images/multimodalreferences.png"
                    class="teaser-image"
                    alt="Multimodal references."
                  />
                </div>
              </div>
            </div>

            <!-- Retractable preference modeling -->
            <div class="box key-point">
              <h3 class="title is-4">Retractable preference modeling</h3>
              <div class="content has-text-justified">
                <p>
                  Our system allows users to revisit previous designs,
                  retracting their earlier choices in the preferential Bayesian
                  optimization process. This feature frees users from the
                  limitations of forward-direction design workflow.
                </p>
              </div>
              <div class="content has-text-centered">
                <div class="content has-text-justified">
                  <img
                    src="./static/images/retractablemodeling.png"
                    class="teaser-image"
                    alt="Retractable preference modeling."
                  />
                </div>
              </div>
            </div>
          </div>
        </div>

        <!--/ Animation. -->

        <!-- Concurrent Work. -->
        <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
        <!--/ Concurrent Work. -->
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{tatsukawa2025fontcraft,
  author    = {Tatsukawa, Yuki and Shen, I-Chao and Dogan, Mustafa Doga and Qi, Anran and Koyama, Yuki and Shamir, Ariel Igarashi, Takeo},
  title     = {FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization},
  journal   = {CHI},
  year      = {2025},
}</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <a
            class="icon-link"
            href="https://jdily.github.io/resource/fontclip/fontCLIP_paper_open.pdf"
          >
            <i class="fas fa-file-pdf"></i>
          </a>
          <a
            class="icon-link"
            href="https://arxiv.org/abs/2403.06453"
            class="external-link"
            disabled
          >
            <i class="ai ai-arxiv"></i>
          </a>
          <a
            class="icon-link"
            href="https://github.com/yukistavailable/FontCLIP"
            class="external-link"
            disabled
          >
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
              <p>
                Website source code based on the
                <a href="https://nerfies.github.io/">Nerfies</a> project page.
                If you want to reuse their
                <a href="https://github.com/nerfies/nerfies.github.io"
                  >source code</a
                >, please credit them appropriately.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
